{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "os.chdir(\"C:\\\\Users\\\\renan\\\\Desktop\\\\full_count_2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('segdata_full.csv')\n",
    "data['X'] = np.array(list(range(1, 101, 1)))\n",
    "gdf = gpd.read_file('dummy_lattice_map.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  A1   A2   B1   B2   C1   C2  D1   D2   E1   E2  F1   F2  G1  \\\n",
       "0         g1   0  100    0  100    0  100   0  100    0  100   0  100   0   \n",
       "1         g2   0  100    0  100  100    0   0  100    0  100   0  100   0   \n",
       "2         g3   0  100    0  100    0  100   0  100   50   50   0  100   0   \n",
       "3         g4   0  100  100    0  100    0   0  100  100    0   0  100   0   \n",
       "4         g5   0  100  100    0    0  100  50   50  100    0   0  100   0   \n",
       "\n",
       "    G2  H1   H2  X  \n",
       "0  100   0  100  1  \n",
       "1  100   0  100  2  \n",
       "2  100   0  100  3  \n",
       "3  100   0  100  4  \n",
       "4  100   0  100  5  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                               geometry\n",
       "0  1  POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))\n",
       "1  2  POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))\n",
       "2  3  POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))\n",
       "3  4  POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))\n",
       "4  5  POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))</td>\n",
       "      <td>g1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))</td>\n",
       "      <td>g2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))</td>\n",
       "      <td>g3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))</td>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))</td>\n",
       "      <td>g5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                               geometry Unnamed: 0  A1   A2   B1   B2  \\\n",
       "0  1  POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))         g1   0  100    0  100   \n",
       "1  2  POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))         g2   0  100    0  100   \n",
       "2  3  POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))         g3   0  100    0  100   \n",
       "3  4  POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))         g4   0  100  100    0   \n",
       "4  5  POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))         g5   0  100  100    0   \n",
       "\n",
       "    C1   C2  D1   D2   E1   E2  F1   F2  G1   G2  H1   H2  \n",
       "0    0  100   0  100    0  100   0  100   0  100   0  100  \n",
       "1  100    0   0  100    0  100   0  100   0  100   0  100  \n",
       "2    0  100   0  100   50   50   0  100   0  100   0  100  \n",
       "3  100    0   0  100  100    0   0  100   0  100   0  100  \n",
       "4    0  100  50   50  100    0   0  100   0  100   0  100  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapa = gdf.merge(data, on='X')\n",
    "df_mapa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar Function\n",
    "def _return_length_weighted_w(data):\n",
    "    \"\"\"\n",
    "    Returns a PySAL weights object that the weights represent the length of the commom boudary of two areal units that share border.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Currently it's not making any projection.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if ('geometry' not in data.columns):    \n",
    "        raise ValueError('The input data has to have a column named \\'geometry\\'')\n",
    "    \n",
    "    data['index'] = data.index\n",
    "    w = libpysal.weights.Queen.from_dataframe(data, ids = data.index.tolist())\n",
    "    \n",
    "    adjlist = w.to_adjlist().merge(data[['index', 'geometry']], left_on='focal', right_on='index', how='left')\\\n",
    "              .drop('index', axis=1)\\\n",
    "              .merge(data[['index', 'geometry']], left_on='neighbor', right_on='index', \n",
    "                     how='left', suffixes=(\"_focal\", \"_neighbor\"))\\\n",
    "              .drop('index', axis=1)\n",
    "    \n",
    "    # Transforming from pandas to geopandas\n",
    "    adjlist = gpd.GeoDataFrame(adjlist, geometry='geometry_focal')\n",
    "    adjlist['geometry_neighbor'] = gpd.GeoSeries(adjlist.geometry_neighbor)\n",
    "    \n",
    "    # Getting the shared boundaries\n",
    "    adjlist['shared_boundary'] = adjlist.geometry_focal.intersection(adjlist.set_geometry('geometry_neighbor'))\n",
    "    \n",
    "    # Putting it back to a matrix\n",
    "    adjlist['weight'] = adjlist.set_geometry('shared_boundary').length\n",
    "    length_weighted_w = libpysal.weights.W.from_adjlist(adjlist[['focal', 'neighbor', 'weight']])\n",
    "    \n",
    "    return length_weighted_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>X</th>\n",
       "      <th>pi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  A1   A2   B1   B2   C1   C2  D1   D2   E1   E2  F1   F2  G1  \\\n",
       "0         g1   0  100    0  100    0  100   0  100    0  100   0  100   0   \n",
       "1         g2   0  100    0  100  100    0   0  100    0  100   0  100   0   \n",
       "2         g3   0  100    0  100    0  100   0  100   50   50   0  100   0   \n",
       "3         g4   0  100  100    0  100    0   0  100  100    0   0  100   0   \n",
       "4         g5   0  100  100    0    0  100  50   50  100    0   0  100   0   \n",
       "\n",
       "    G2  H1   H2  X   pi  \n",
       "0  100   0  100  1  0.0  \n",
       "1  100   0  100  2  0.0  \n",
       "2  100   0  100  3  0.5  \n",
       "3  100   0  100  4  1.0  \n",
       "4  100   0  100  5  1.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pi'] = data['E1'] / (data['E1'] + data['E2'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.270833333333332"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dij = _return_length_weighted_w(df_mapa).full()[0]\n",
    "wij = dij / np.sum(dij, axis = 1)\n",
    "\n",
    "BSD = D - (1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()\n",
    "BSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.270833333333332"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.33333333, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5       , 0.        , 0.33333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.33333333, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.33333333, 0.        ,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.33333333,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305555555555555"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cij = dij\n",
    "# manhattan_distances used to compute absolute distances\n",
    "num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "den = cij.sum()\n",
    "SD = D - num / den\n",
    "SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "__all__ = ['Dissim']\n",
    "\n",
    "\n",
    "def _dissim(data, group_pop_var, total_pop_var):\n",
    "    \"\"\"\n",
    "    Calculation of Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a pandas DataFrame\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Based on Massey, Douglas S., and Nancy A. Denton. \"The dimensions of residential segregation.\" Social forces 67.2 (1988): 281-315.\n",
    "\n",
    "    \"\"\"\n",
    "    if((type(group_pop_var) is not str) or (type(total_pop_var) is not str)):\n",
    "        raise TypeError('group_pop_var and total_pop_var must be strings')\n",
    "    \n",
    "    if ((group_pop_var not in data.columns) or (total_pop_var not in data.columns)):    \n",
    "        raise ValueError('group_pop_var and total_pop_var must be variables of data')\n",
    "        \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    if any(data.total_pop_var < data.group_pop_var):    \n",
    "        raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "   \n",
    "    T = data.total_pop_var.sum()\n",
    "    P = data.group_pop_var.sum() / T\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "    \n",
    "    D = (((data.total_pop_var * abs(data.pi - P)))/ (2 * T * P * (1 - P))).sum()\n",
    "    \n",
    "    return D\n",
    "\n",
    "\n",
    "class Dissim:\n",
    "    \"\"\"\n",
    "    Classic Dissimilarity Index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a pandas DataFrame\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of dissimilarity (D) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['pop10','nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> dissim_index = Dissim(df, 'nhblk10', 'pop10')\n",
    "    >>> dissim_index.statistic\n",
    "    0.31565682496226544\n",
    "    \n",
    "    The interpretation of this value is that 31.57% of the non-hispanic black population would have to move to reach eveness in the Riverside County.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Based on Massey, Douglas S., and Nancy A. Denton. \"The dimensions of residential segregation.\" Social forces 67.2 (1988): 281-315.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var):\n",
    "\n",
    "        self.statistic = _dissim(data, group_pop_var, total_pop_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spatial Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import libpysal\n",
    "from libpysal.weights import Queen\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "__all__ = ['Spatial_Dissim']\n",
    "\n",
    "\n",
    "def _spatial_dissim(data, group_pop_var, total_pop_var, w = None, std = False):\n",
    "    \"\"\"\n",
    "    Calculation of Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    w             : W\n",
    "                    A PySAL weights object. If not provided, Queen contiguity matrix is used.\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for row standardisation of the weights matrices. If True, the values of cij in the formulas gets row standardized.\n",
    "                    For the sake of comparison, the seg R package of Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "                    works by default with row standardization.\n",
    "        \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Spatial Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Based on Morrill, R. L. (1991) \"On the Measure of Geographic Segregation\". Geography Research Forum.\n",
    "\n",
    "    \"\"\"\n",
    "    if((type(group_pop_var) is not str) or (type(total_pop_var) is not str)):\n",
    "        raise TypeError('group_pop_var and total_pop_var must be strings')\n",
    "    \n",
    "    if ((group_pop_var not in data.columns) or (total_pop_var not in data.columns)):    \n",
    "        raise ValueError('group_pop_var and total_pop_var must be variables of data')\n",
    "        \n",
    "    if w is None:    \n",
    "        w_object = Queen.from_dataframe(data)\n",
    "    else:\n",
    "        w_object = w\n",
    "    \n",
    "    if (not issubclass(type(w_object), libpysal.weights.W)):\n",
    "        raise TypeError('w is not a PySAL weights object')\n",
    "    \n",
    "    if (type(std) is not bool):\n",
    "        raise TypeError('std is not a boolean object')\n",
    "    \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    if any(data.total_pop_var < data.group_pop_var):    \n",
    "        raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "   \n",
    "    T = data.total_pop_var.sum()\n",
    "    P = data.group_pop_var.sum() / T\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "    \n",
    "    D = (((data.total_pop_var * abs(data.pi - P)))/ (2 * T * P * (1 - P))).sum()\n",
    "    \n",
    "    if not std:\n",
    "        cij = w_object.full()[0]\n",
    "    else:\n",
    "        cij = w_object.full()[0]\n",
    "        cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "\n",
    "    # manhattan_distances used to compute absolute distances\n",
    "    num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "    den = cij.sum()\n",
    "    SD = D - num / den\n",
    "    SD\n",
    "    \n",
    "    return SD\n",
    "\n",
    "\n",
    "class Spatial_Dissim:\n",
    "    \"\"\"\n",
    "    Calculation of Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    w             : W\n",
    "                    A PySAL weights object. If not provided, Queen contiguity matrix is used.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Spatial Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of spatial dissimilarity (D) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset. The neighborhood contiguity matrix is used.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "    \n",
    "    Then, we read the Riverside map data using geopandas (the county id is 06065):\n",
    "    \n",
    "    >>> map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "    >>> map_gpd = gpd.read_file(map_url)\n",
    "    \n",
    "    It is necessary to harmonize the data type of the dataset and the geopandas in order to work the merging procedure.\n",
    "    Later, we extract only the columns that will be used.\n",
    "    \n",
    "    >>> map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "    >>> gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "    >>> gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> spatial_dissim_index = Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "    >>> spatial_dissim_index.statistic\n",
    "    0.2864885055405311\n",
    "        \n",
    "    To use different neighborhood matrices:\n",
    "        \n",
    "    >>> from libpysal.weights import Rook, KNN\n",
    "    \n",
    "    Assuming K-nearest neighbors with k = 4\n",
    "    \n",
    "    >>> knn = KNN.from_dataframe(gdf, k=4)\n",
    "    >>> spatial_dissim_index = Spatial_Dissim(gdf, 'nhblk10', 'pop10', w = knn)\n",
    "    >>> spatial_dissim_index.statistic\n",
    "    0.28544347200877285\n",
    "    \n",
    "    Assuming Rook contiguity neighborhood\n",
    "    \n",
    "    >>> roo = Rook.from_dataframe(gdf)\n",
    "    >>> spatial_dissim_index = Spatial_Dissim(gdf, 'nhblk10', 'pop10', w = roo)\n",
    "    >>> spatial_dissim_index.statistic\n",
    "    0.2866269198707091\n",
    "            \n",
    "    Notes\n",
    "    -----\n",
    "    Based on Morrill, R. L. (1991) \"On the Measure of Geographic Segregation\". Geography Research Forum.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var, w = None, std = False):\n",
    "\n",
    "        self.statistic = _spatial_dissim(data, group_pop_var, total_pop_var, w, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assymetric Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('SegP5.shp')\n",
    "gdf['total'] = gdf['grp1'] + gdf['grp2']\n",
    "gdf['total'] = gdf['grp1'] + gdf['grp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp1</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grp1    grp2                                           geometry   total\n",
       "0    0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...  2500.0\n",
       "1  900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   900.0\n",
       "2    0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...  1600.0\n",
       "3    0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...  2500.0\n",
       "4    0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...  2500.0"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = Dissim(gdf, 'grp1', 'total').statistic\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dadj = Spatial_Dissim(gdf, 'grp1', 'total', std = True).statistic\n",
    "Dadj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236e2a07438>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf.plot('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pop_var</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_pop_var</th>\n",
       "      <th>pi</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_pop_var    grp2                                           geometry  \\\n",
       "0            0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...   \n",
       "1          900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   \n",
       "2            0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...   \n",
       "3            0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...   \n",
       "4            0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...   \n",
       "\n",
       "   total_pop_var   pi  index  \n",
       "0         2500.0  0.0      0  \n",
       "1          900.0  1.0      1  \n",
       "2         1600.0  0.0      2  \n",
       "3         2500.0  0.0      3  \n",
       "4         2500.0  0.0      4  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pop_var</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_pop_var</th>\n",
       "      <th>pi</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_pop_var    grp2                                           geometry  \\\n",
       "0            0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...   \n",
       "1          900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   \n",
       "2            0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...   \n",
       "3            0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...   \n",
       "4            0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...   \n",
       "\n",
       "   total_pop_var   pi  index  \n",
       "0         2500.0  0.0      0  \n",
       "1          900.0  1.0      1  \n",
       "2         1600.0  0.0      2  \n",
       "3         2500.0  0.0      3  \n",
       "4         2500.0  0.0      4  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={'grp1': 'group_pop_var', \n",
    "                            'total': 'total_pop_var'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'grp1': 'group_pop_var', \n",
    "                            'total': 'total_pop_var'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.rename(columns={grp1: 'group_pop_var', \n",
    "#                           total: 'total_pop_var'})\n",
    "\n",
    "if any(data.total_pop_var < data.group_pop_var):    \n",
    "    raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "\n",
    "T = data.total_pop_var.sum()\n",
    "P = data.group_pop_var.sum() / T\n",
    "\n",
    "# If a unit has zero population, the group of interest frequency is zero\n",
    "data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pop_var</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_pop_var</th>\n",
       "      <th>pi</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_pop_var    grp2                                           geometry  \\\n",
       "0            0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...   \n",
       "1          900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   \n",
       "2            0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...   \n",
       "3            0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...   \n",
       "4            0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...   \n",
       "\n",
       "   total_pop_var   pi  index  \n",
       "0         2500.0  0.0      0  \n",
       "1          900.0  1.0      1  \n",
       "2         1600.0  0.0      2  \n",
       "3         2500.0  0.0      3  \n",
       "4         2500.0  0.0      4  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.27777778, 0.        , 0.44444444, 0.        , 0.27777778],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       , 0.        ]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " D - (1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_distances(data[['pi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(manhattan_distances(data[['pi']]), wij).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 5., 0., 5., 0.],\n",
       "       [5., 0., 8., 0., 5.],\n",
       "       [0., 8., 0., 0., 0.],\n",
       "       [5., 0., 0., 0., 5.],\n",
       "       [0., 5., 0., 5., 0.]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dij = _return_length_weighted_w(data).full()[0]\n",
    "wij = dij / np.sum(dij, axis = 1).reshape((dij.shape[0], 1))\n",
    "\n",
    "BSD = D - (1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()\n",
    "BSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3571428571612103"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cij = _return_length_weighted_w(data).full()[0]\n",
    "#cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "\n",
    "# manhattan_distances used to compute absolute distances\n",
    "num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "den = cij.sum()\n",
    "BSD_aux = D - num / den\n",
    "BSD_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boundary Spatial Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import libpysal\n",
    "#from util import _return_length_weighted_w\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "__all__ = ['Boundary_Spatial_Dissim']\n",
    "\n",
    "\n",
    "def _boundary_spatial_dissim(data, group_pop_var, total_pop_var, std = False):\n",
    "    \"\"\"\n",
    "    Calculation of Boundary Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for row standardisation of the weights matrices. If True, the values of cij in the formulas gets row standardized.\n",
    "                    For the sake of comparison, the seg R package of Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "                    works by default without row standardization. That is, directly with border length.\n",
    "        \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Boundary Spatial Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The formula is based on Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "    \n",
    "    Original paper by Wong, David WS. \"Spatial indices of segregation.\" Urban studies 30.3 (1993): 559-572.\n",
    "\n",
    "    \"\"\"\n",
    "    if((type(group_pop_var) is not str) or (type(total_pop_var) is not str)):\n",
    "        raise TypeError('group_pop_var and total_pop_var must be strings')\n",
    "    \n",
    "    if ((group_pop_var not in data.columns) or (total_pop_var not in data.columns)):    \n",
    "        raise ValueError('group_pop_var and total_pop_var must be variables of data')\n",
    "    \n",
    "    if (type(std) is not bool):\n",
    "        raise TypeError('std is not a boolean object')\n",
    "    \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    if any(data.total_pop_var < data.group_pop_var):    \n",
    "        raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "   \n",
    "    T = data.total_pop_var.sum()\n",
    "    P = data.group_pop_var.sum() / T\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "    \n",
    "    D = (((data.total_pop_var * abs(data.pi - P)))/ (2 * T * P * (1 - P))).sum()\n",
    "    \n",
    "    if not std:\n",
    "        cij = _return_length_weighted_w(data).full()[0]\n",
    "    else:\n",
    "        cij = _return_length_weighted_w(data).full()[0]\n",
    "        cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "\n",
    "    # manhattan_distances used to compute absolute distances\n",
    "    num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "    den = cij.sum()\n",
    "    BSD = D - num / den\n",
    "    BSD\n",
    "    \n",
    "    return BSD\n",
    "\n",
    "\n",
    "class Boundary_Spatial_Dissim:\n",
    "    \"\"\"\n",
    "    Calculation of Boundary Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for row standardisation of the weights matrices. If True, the values of cij in the formulas gets row standardized.\n",
    "                    For the sake of comparison, the seg R package of Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "                    works by default without row standardization. That is, directly with border length.\n",
    "        \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Boundary Spatial Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of boundary spatial dissimilarity (D) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset. The neighborhood contiguity matrix is used.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "    \n",
    "    Then, we read the Riverside map data using geopandas (the county id is 06065):\n",
    "    \n",
    "    >>> map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "    >>> map_gpd = gpd.read_file(map_url)\n",
    "    \n",
    "    It is necessary to harmonize the data type of the dataset and the geopandas in order to work the merging procedure.\n",
    "    Later, we extract only the columns that will be used.\n",
    "    \n",
    "    >>> map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "    >>> gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "    >>> gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> boundary_spatial_dissim_index = Boundary_Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "    >>> boundary_spatial_dissim_index.statistic\n",
    "    xxxxx\n",
    "            \n",
    "    Notes\n",
    "    -----\n",
    "    The formula is based on Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "    \n",
    "    Original paper by Wong, David WS. \"Spatial indices of segregation.\" Urban studies 30.3 (1993): 559-572.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var, std = False):\n",
    "\n",
    "        self.statistic = _boundary_spatial_dissim(data, group_pop_var, total_pop_var, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384189712"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('SegP4.shp')\n",
    "gdf['total'] = gdf['grp1'] + gdf['grp2']\n",
    "Boundary_Spatial_Dissim(gdf, 'grp1', 'total').statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28869903953453163"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "map_gpd = gpd.read_file(map_url)\n",
    "map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "boundary_spatial_dissim_index = Boundary_Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "boundary_spatial_dissim_index.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
