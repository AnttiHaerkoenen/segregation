{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "os.chdir(\"C:\\\\Users\\\\renan\\\\Desktop\\\\full_count_2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('segdata_full.csv')\n",
    "data['X'] = np.array(list(range(1, 101, 1)))\n",
    "gdf = gpd.read_file('dummy_lattice_map.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  A1   A2   B1   B2   C1   C2  D1   D2   E1   E2  F1   F2  G1  \\\n",
       "0         g1   0  100    0  100    0  100   0  100    0  100   0  100   0   \n",
       "1         g2   0  100    0  100  100    0   0  100    0  100   0  100   0   \n",
       "2         g3   0  100    0  100    0  100   0  100   50   50   0  100   0   \n",
       "3         g4   0  100  100    0  100    0   0  100  100    0   0  100   0   \n",
       "4         g5   0  100  100    0    0  100  50   50  100    0   0  100   0   \n",
       "\n",
       "    G2  H1   H2  X  \n",
       "0  100   0  100  1  \n",
       "1  100   0  100  2  \n",
       "2  100   0  100  3  \n",
       "3  100   0  100  4  \n",
       "4  100   0  100  5  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                               geometry\n",
       "0  1  POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))\n",
       "1  2  POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))\n",
       "2  3  POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))\n",
       "3  4  POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))\n",
       "4  5  POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))</td>\n",
       "      <td>g1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))</td>\n",
       "      <td>g2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))</td>\n",
       "      <td>g3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))</td>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))</td>\n",
       "      <td>g5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                               geometry Unnamed: 0  A1   A2   B1   B2  \\\n",
       "0  1  POLYGON ((0 9, 0 10, 1 10, 1 9, 0 9))         g1   0  100    0  100   \n",
       "1  2  POLYGON ((1 9, 1 10, 2 10, 2 9, 1 9))         g2   0  100    0  100   \n",
       "2  3  POLYGON ((2 9, 2 10, 3 10, 3 9, 2 9))         g3   0  100    0  100   \n",
       "3  4  POLYGON ((3 9, 3 10, 4 10, 4 9, 3 9))         g4   0  100  100    0   \n",
       "4  5  POLYGON ((4 9, 4 10, 5 10, 5 9, 4 9))         g5   0  100  100    0   \n",
       "\n",
       "    C1   C2  D1   D2   E1   E2  F1   F2  G1   G2  H1   H2  \n",
       "0    0  100   0  100    0  100   0  100   0  100   0  100  \n",
       "1  100    0   0  100    0  100   0  100   0  100   0  100  \n",
       "2    0  100   0  100   50   50   0  100   0  100   0  100  \n",
       "3  100    0   0  100  100    0   0  100   0  100   0  100  \n",
       "4    0  100  50   50  100    0   0  100   0  100   0  100  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapa = gdf.merge(data, on='X')\n",
    "df_mapa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar Function\n",
    "def _return_length_weighted_w(data):\n",
    "    \"\"\"\n",
    "    Returns a PySAL weights object that the weights represent the length of the commom boudary of two areal units that share border.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Currently it's not making any projection.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if ('geometry' not in data.columns):    \n",
    "        raise ValueError('The input data has to have a column named \\'geometry\\'')\n",
    "    \n",
    "    data['index'] = data.index\n",
    "    w = libpysal.weights.Queen.from_dataframe(data, ids = data.index.tolist())\n",
    "    \n",
    "    adjlist = w.to_adjlist().merge(data[['index', 'geometry']], left_on='focal', right_on='index', how='left')\\\n",
    "              .drop('index', axis=1)\\\n",
    "              .merge(data[['index', 'geometry']], left_on='neighbor', right_on='index', \n",
    "                     how='left', suffixes=(\"_focal\", \"_neighbor\"))\\\n",
    "              .drop('index', axis=1)\n",
    "    \n",
    "    # Transforming from pandas to geopandas\n",
    "    adjlist = gpd.GeoDataFrame(adjlist, geometry='geometry_focal')\n",
    "    adjlist['geometry_neighbor'] = gpd.GeoSeries(adjlist.geometry_neighbor)\n",
    "    \n",
    "    # Getting the shared boundaries\n",
    "    adjlist['shared_boundary'] = adjlist.geometry_focal.intersection(adjlist.set_geometry('geometry_neighbor'))\n",
    "    \n",
    "    # Putting it back to a matrix\n",
    "    adjlist['weight'] = adjlist.set_geometry('shared_boundary').length\n",
    "    length_weighted_w = libpysal.weights.W.from_adjlist(adjlist[['focal', 'neighbor', 'weight']])\n",
    "    \n",
    "    return length_weighted_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>X</th>\n",
       "      <th>pi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  A1   A2   B1   B2   C1   C2  D1   D2   E1   E2  F1   F2  G1  \\\n",
       "0         g1   0  100    0  100    0  100   0  100    0  100   0  100   0   \n",
       "1         g2   0  100    0  100  100    0   0  100    0  100   0  100   0   \n",
       "2         g3   0  100    0  100    0  100   0  100   50   50   0  100   0   \n",
       "3         g4   0  100  100    0  100    0   0  100  100    0   0  100   0   \n",
       "4         g5   0  100  100    0    0  100  50   50  100    0   0  100   0   \n",
       "\n",
       "    G2  H1   H2  X   pi  \n",
       "0  100   0  100  1  0.0  \n",
       "1  100   0  100  2  0.0  \n",
       "2  100   0  100  3  0.5  \n",
       "3  100   0  100  4  1.0  \n",
       "4  100   0  100  5  1.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pi'] = data['E1'] / (data['E1'] + data['E2'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.270833333333332"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dij = _return_length_weighted_w(df_mapa).full()[0]\n",
    "wij = dij / np.sum(dij, axis = 1)\n",
    "\n",
    "BSD = D - (1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()\n",
    "BSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.270833333333332"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.33333333, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5       , 0.        , 0.33333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.33333333, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.33333333, 0.        ,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.33333333,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305555555555555"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cij = dij\n",
    "# manhattan_distances used to compute absolute distances\n",
    "num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "den = cij.sum()\n",
    "SD = D - num / den\n",
    "SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "__all__ = ['Dissim']\n",
    "\n",
    "\n",
    "def _dissim(data, group_pop_var, total_pop_var):\n",
    "    \"\"\"\n",
    "    Calculation of Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a pandas DataFrame\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Based on Massey, Douglas S., and Nancy A. Denton. \"The dimensions of residential segregation.\" Social forces 67.2 (1988): 281-315.\n",
    "\n",
    "    \"\"\"\n",
    "    if((type(group_pop_var) is not str) or (type(total_pop_var) is not str)):\n",
    "        raise TypeError('group_pop_var and total_pop_var must be strings')\n",
    "    \n",
    "    if ((group_pop_var not in data.columns) or (total_pop_var not in data.columns)):    \n",
    "        raise ValueError('group_pop_var and total_pop_var must be variables of data')\n",
    "        \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    if any(data.total_pop_var < data.group_pop_var):    \n",
    "        raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "   \n",
    "    T = data.total_pop_var.sum()\n",
    "    P = data.group_pop_var.sum() / T\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "    \n",
    "    D = (((data.total_pop_var * abs(data.pi - P)))/ (2 * T * P * (1 - P))).sum()\n",
    "    \n",
    "    return D\n",
    "\n",
    "\n",
    "class Dissim:\n",
    "    \"\"\"\n",
    "    Classic Dissimilarity Index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a pandas DataFrame\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of dissimilarity (D) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['pop10','nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> dissim_index = Dissim(df, 'nhblk10', 'pop10')\n",
    "    >>> dissim_index.statistic\n",
    "    0.31565682496226544\n",
    "    \n",
    "    The interpretation of this value is that 31.57% of the non-hispanic black population would have to move to reach eveness in the Riverside County.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Based on Massey, Douglas S., and Nancy A. Denton. \"The dimensions of residential segregation.\" Social forces 67.2 (1988): 281-315.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var):\n",
    "\n",
    "        self.statistic = _dissim(data, group_pop_var, total_pop_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spatial Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import libpysal\n",
    "from libpysal.weights import Queen\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "__all__ = ['Spatial_Dissim']\n",
    "\n",
    "\n",
    "def _spatial_dissim(data, group_pop_var, total_pop_var, w = None, std = False):\n",
    "    \"\"\"\n",
    "    Calculation of Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    w             : W\n",
    "                    A PySAL weights object. If not provided, Queen contiguity matrix is used.\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for row standardisation of the weights matrices. If True, the values of cij in the formulas gets row standardized.\n",
    "                    For the sake of comparison, the seg R package of Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "                    works by default with row standardization.\n",
    "        \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Spatial Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Based on Morrill, R. L. (1991) \"On the Measure of Geographic Segregation\". Geography Research Forum.\n",
    "\n",
    "    \"\"\"\n",
    "    if((type(group_pop_var) is not str) or (type(total_pop_var) is not str)):\n",
    "        raise TypeError('group_pop_var and total_pop_var must be strings')\n",
    "    \n",
    "    if ((group_pop_var not in data.columns) or (total_pop_var not in data.columns)):    \n",
    "        raise ValueError('group_pop_var and total_pop_var must be variables of data')\n",
    "        \n",
    "    if w is None:    \n",
    "        w_object = Queen.from_dataframe(data)\n",
    "    else:\n",
    "        w_object = w\n",
    "    \n",
    "    if (not issubclass(type(w_object), libpysal.weights.W)):\n",
    "        raise TypeError('w is not a PySAL weights object')\n",
    "    \n",
    "    if (type(std) is not bool):\n",
    "        raise TypeError('std is not a boolean object')\n",
    "    \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    if any(data.total_pop_var < data.group_pop_var):    \n",
    "        raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "   \n",
    "    T = data.total_pop_var.sum()\n",
    "    P = data.group_pop_var.sum() / T\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "    \n",
    "    D = (((data.total_pop_var * abs(data.pi - P)))/ (2 * T * P * (1 - P))).sum()\n",
    "    \n",
    "    if not std:\n",
    "        cij = w_object.full()[0]\n",
    "    else:\n",
    "        cij = w_object.full()[0]\n",
    "        cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "\n",
    "    # manhattan_distances used to compute absolute distances\n",
    "    num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "    den = cij.sum()\n",
    "    SD = D - num / den\n",
    "    SD\n",
    "    \n",
    "    return SD\n",
    "\n",
    "\n",
    "class Spatial_Dissim:\n",
    "    \"\"\"\n",
    "    Calculation of Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    w             : W\n",
    "                    A PySAL weights object. If not provided, Queen contiguity matrix is used.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Spatial Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of spatial dissimilarity (D) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset. The neighborhood contiguity matrix is used.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "    \n",
    "    Then, we read the Riverside map data using geopandas (the county id is 06065):\n",
    "    \n",
    "    >>> map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "    >>> map_gpd = gpd.read_file(map_url)\n",
    "    \n",
    "    It is necessary to harmonize the data type of the dataset and the geopandas in order to work the merging procedure.\n",
    "    Later, we extract only the columns that will be used.\n",
    "    \n",
    "    >>> map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "    >>> gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "    >>> gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> spatial_dissim_index = Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "    >>> spatial_dissim_index.statistic\n",
    "    0.2864885055405311\n",
    "        \n",
    "    To use different neighborhood matrices:\n",
    "        \n",
    "    >>> from libpysal.weights import Rook, KNN\n",
    "    \n",
    "    Assuming K-nearest neighbors with k = 4\n",
    "    \n",
    "    >>> knn = KNN.from_dataframe(gdf, k=4)\n",
    "    >>> spatial_dissim_index = Spatial_Dissim(gdf, 'nhblk10', 'pop10', w = knn)\n",
    "    >>> spatial_dissim_index.statistic\n",
    "    0.28544347200877285\n",
    "    \n",
    "    Assuming Rook contiguity neighborhood\n",
    "    \n",
    "    >>> roo = Rook.from_dataframe(gdf)\n",
    "    >>> spatial_dissim_index = Spatial_Dissim(gdf, 'nhblk10', 'pop10', w = roo)\n",
    "    >>> spatial_dissim_index.statistic\n",
    "    0.2866269198707091\n",
    "            \n",
    "    Notes\n",
    "    -----\n",
    "    Based on Morrill, R. L. (1991) \"On the Measure of Geographic Segregation\". Geography Research Forum.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var, w = None, std = False):\n",
    "\n",
    "        self.statistic = _spatial_dissim(data, group_pop_var, total_pop_var, w, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assymetric Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('SegP2.shp')\n",
    "gdf['total'] = gdf['grp1'] + gdf['grp2']\n",
    "gdf['total'] = gdf['grp1'] + gdf['grp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp1</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((3.999973999900192 6.999974000199927,...</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>POLYGON ((2.999974000099996 7.999974000000066,...</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((8.999973999800261 6.999974000199927,...</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>POLYGON ((7.999974000000066 7.999974000000066,...</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((3.999973999900192 1.999974000299858,...</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grp1    grp2                                           geometry   total\n",
       "0  600.0     0.0  POLYGON ((3.999973999900192 6.999974000199927,...   600.0\n",
       "1    0.0  1900.0  POLYGON ((2.999974000099996 7.999974000000066,...  1900.0\n",
       "2  600.0     0.0  POLYGON ((8.999973999800261 6.999974000199927,...   600.0\n",
       "3    0.0  1900.0  POLYGON ((7.999974000000066 7.999974000000066,...  1900.0\n",
       "4  600.0     0.0  POLYGON ((3.999973999900192 1.999974000299858,...   600.0"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = Dissim(gdf, 'grp1', 'total').statistic\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236e2c94550>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf.plot(column = 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3571428571428571"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dadj = Spatial_Dissim(gdf, 'grp1', 'total', std = False).statistic\n",
    "Dadj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.27777778, 0.        , 0.44444444, 0.        , 0.27777778],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       , 0.        ]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gdf\n",
    "cij = _return_length_weighted_w(data).full()[0]\n",
    "cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "cij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236e2a07438>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf.plot('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pop_var</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_pop_var</th>\n",
       "      <th>pi</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_pop_var    grp2                                           geometry  \\\n",
       "0            0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...   \n",
       "1          900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   \n",
       "2            0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...   \n",
       "3            0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...   \n",
       "4            0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...   \n",
       "\n",
       "   total_pop_var   pi  index  \n",
       "0         2500.0  0.0      0  \n",
       "1          900.0  1.0      1  \n",
       "2         1600.0  0.0      2  \n",
       "3         2500.0  0.0      3  \n",
       "4         2500.0  0.0      4  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pop_var</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_pop_var</th>\n",
       "      <th>pi</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_pop_var    grp2                                           geometry  \\\n",
       "0            0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...   \n",
       "1          900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   \n",
       "2            0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...   \n",
       "3            0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...   \n",
       "4            0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...   \n",
       "\n",
       "   total_pop_var   pi  index  \n",
       "0         2500.0  0.0      0  \n",
       "1          900.0  1.0      1  \n",
       "2         1600.0  0.0      2  \n",
       "3         2500.0  0.0      3  \n",
       "4         2500.0  0.0      4  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={'grp1': 'group_pop_var', \n",
    "                            'total': 'total_pop_var'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'grp1': 'group_pop_var', \n",
    "                            'total': 'total_pop_var'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.rename(columns={grp1: 'group_pop_var', \n",
    "#                           total: 'total_pop_var'})\n",
    "\n",
    "if any(data.total_pop_var < data.group_pop_var):    \n",
    "    raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "\n",
    "T = data.total_pop_var.sum()\n",
    "P = data.group_pop_var.sum() / T\n",
    "\n",
    "# If a unit has zero population, the group of interest frequency is zero\n",
    "data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pop_var</th>\n",
       "      <th>grp2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_pop_var</th>\n",
       "      <th>pi</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 4.99997399970033,...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 6.999974000199927,...</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>POLYGON ((6.999974000199927 5.999974000399789,...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((0.9999739996003996 -2.60001997389736...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POLYGON ((5.999974000399789 -2.600019973897361...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_pop_var    grp2                                           geometry  \\\n",
       "0            0.0  2500.0  POLYGON ((0.9999739996003996 4.99997399970033,...   \n",
       "1          900.0     0.0  POLYGON ((5.999974000399789 6.999974000199927,...   \n",
       "2            0.0  1600.0  POLYGON ((6.999974000199927 5.999974000399789,...   \n",
       "3            0.0  2500.0  POLYGON ((0.9999739996003996 -2.60001997389736...   \n",
       "4            0.0  2500.0  POLYGON ((5.999974000399789 -2.600019973897361...   \n",
       "\n",
       "   total_pop_var   pi  index  \n",
       "0         2500.0  0.0      0  \n",
       "1          900.0  1.0      1  \n",
       "2         1600.0  0.0      2  \n",
       "3         2500.0  0.0      3  \n",
       "4         2500.0  0.0      4  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.27777778, 0.        , 0.44444444, 0.        , 0.27777778],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       , 0.        ]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " D - (1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_distances(data[['pi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(manhattan_distances(data[['pi']]), wij).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 5., 0., 5., 0.],\n",
       "       [5., 0., 8., 0., 5.],\n",
       "       [0., 8., 0., 0., 0.],\n",
       "       [5., 0., 0., 0., 5.],\n",
       "       [0., 5., 0., 5., 0.]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dij = _return_length_weighted_w(data).full()[0]\n",
    "wij = dij / np.sum(dij, axis = 1).reshape((dij.shape[0], 1))\n",
    "\n",
    "BSD = D - (1 / 2) * np.multiply(manhattan_distances(data[['pi']]), wij).sum()\n",
    "BSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3571428571612103"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cij = _return_length_weighted_w(data).full()[0]\n",
    "#cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "\n",
    "# manhattan_distances used to compute absolute distances\n",
    "num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "den = cij.sum()\n",
    "BSD_aux = D - num / den\n",
    "BSD_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boundary Spatial Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import libpysal\n",
    "#from util import _return_length_weighted_w\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "__all__ = ['Boundary_Spatial_Dissim']\n",
    "\n",
    "\n",
    "def _boundary_spatial_dissim(data, group_pop_var, total_pop_var, std = False):\n",
    "    \"\"\"\n",
    "    Calculation of Boundary Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for row standardisation of the weights matrices. If True, the values of cij in the formulas gets row standardized.\n",
    "                    For the sake of comparison, the seg R package of Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "                    works by default without row standardization. That is, directly with border length.\n",
    "        \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Boundary Spatial Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The formula is based on Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "    \n",
    "    Original paper by Wong, David WS. \"Spatial indices of segregation.\" Urban studies 30.3 (1993): 559-572.\n",
    "\n",
    "    \"\"\"\n",
    "    if((type(group_pop_var) is not str) or (type(total_pop_var) is not str)):\n",
    "        raise TypeError('group_pop_var and total_pop_var must be strings')\n",
    "    \n",
    "    if ((group_pop_var not in data.columns) or (total_pop_var not in data.columns)):    \n",
    "        raise ValueError('group_pop_var and total_pop_var must be variables of data')\n",
    "    \n",
    "    if (type(std) is not bool):\n",
    "        raise TypeError('std is not a boolean object')\n",
    "    \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    if any(data.total_pop_var < data.group_pop_var):    \n",
    "        raise ValueError('Group of interest population must equal or lower than the total population of the units.')\n",
    "   \n",
    "    T = data.total_pop_var.sum()\n",
    "    P = data.group_pop_var.sum() / T\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "    \n",
    "    D = (((data.total_pop_var * abs(data.pi - P)))/ (2 * T * P * (1 - P))).sum()\n",
    "    \n",
    "    if not std:\n",
    "        cij = _return_length_weighted_w(data).full()[0]\n",
    "    else:\n",
    "        cij = _return_length_weighted_w(data).full()[0]\n",
    "        cij = cij / cij.sum(axis = 1).reshape((cij.shape[0], 1))\n",
    "\n",
    "    # manhattan_distances used to compute absolute distances\n",
    "    #num = np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "    #den = cij.sum()\n",
    "    #BSD = D - num / den\n",
    "    BSD = D - (1/2) * np.multiply(manhattan_distances(data[['pi']]), cij).sum()\n",
    "    BSD\n",
    "    \n",
    "    return BSD\n",
    "\n",
    "\n",
    "class Boundary_Spatial_Dissim:\n",
    "    \"\"\"\n",
    "    Calculation of Boundary Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for row standardisation of the weights matrices. If True, the values of cij in the formulas gets row standardized.\n",
    "                    For the sake of comparison, the seg R package of Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "                    works by default without row standardization. That is, directly with border length.\n",
    "        \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Boundary Spatial Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of boundary spatial dissimilarity (D) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset. The neighborhood contiguity matrix is used.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "    \n",
    "    Then, we read the Riverside map data using geopandas (the county id is 06065):\n",
    "    \n",
    "    >>> map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "    >>> map_gpd = gpd.read_file(map_url)\n",
    "    \n",
    "    It is necessary to harmonize the data type of the dataset and the geopandas in order to work the merging procedure.\n",
    "    Later, we extract only the columns that will be used.\n",
    "    \n",
    "    >>> map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "    >>> gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "    >>> gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> boundary_spatial_dissim_index = Boundary_Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "    >>> boundary_spatial_dissim_index.statistic\n",
    "    xxxxx\n",
    "            \n",
    "    Notes\n",
    "    -----\n",
    "    The formula is based on Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "    \n",
    "    Original paper by Wong, David WS. \"Spatial indices of segregation.\" Urban studies 30.3 (1993): 559-572.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var, std = False):\n",
    "\n",
    "        self.statistic = _boundary_spatial_dissim(data, group_pop_var, total_pop_var, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('SegP1.shp')\n",
    "gdf['total'] = gdf['grp1'] + gdf['grp2']\n",
    "# In Wong (1993) they establish the neighbors differently\n",
    "Spatial_Dissim(gdf, 'grp1', 'total', std = True).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boundary_Spatial_Dissim(gdf, 'grp1', 'total', std = False).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499999999999999"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perimeter_Area_Ratio_Spatial_Dissim(gdf, 'grp1', 'total', std = True).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236ed26db38>"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf.plot(column = 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28869903953453163"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "map_gpd = gpd.read_file(map_url)\n",
    "map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "boundary_spatial_dissim_index = Boundary_Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "boundary_spatial_dissim_index.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perimeter/Area Ratio Spatial Dissimilarity based Segregation Metrics\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Renan X. Cortes <renanc@ucr.edu> and Sergio J. Rey <sergio.rey@ucr.edu>\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import libpysal\n",
    "from util import _return_length_weighted_w\n",
    "from dissimilarity import _dissim\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "__all__ = ['Perimeter_Area_Ratio_Spatial_Dissim']\n",
    "\n",
    "\n",
    "def _perimeter_area_ratio_spatial_dissim(data, group_pop_var, total_pop_var, std = True):\n",
    "    \"\"\"\n",
    "    Calculation of Perimeter/Area Ratio Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for standardisation of the weights matrices. \n",
    "                    If True, the values of cij in the formulas gets standardized and the overall sum is 1.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Perimeter/Area Ratio Spatial Dissimilarity Index\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The formula is based on Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "    \n",
    "    Original paper by Wong, David WS. \"Spatial indices of segregation.\" Urban studies 30.3 (1993): 559-572.\n",
    "\n",
    "    \"\"\"\n",
    "    if (type(std) is not bool):\n",
    "        raise TypeError('std is not a boolean object')\n",
    "    \n",
    "    D = _dissim(data, group_pop_var, total_pop_var)\n",
    "    \n",
    "    data = data.rename(columns={group_pop_var: 'group_pop_var', \n",
    "                                total_pop_var: 'total_pop_var'})\n",
    "    \n",
    "    # If a unit has zero population, the group of interest frequency is zero\n",
    "    data = data.assign(pi = np.where(data.total_pop_var == 0, 0, data.group_pop_var/data.total_pop_var))\n",
    "\n",
    "    if not std:\n",
    "        cij = _return_length_weighted_w(data).full()[0]\n",
    "    else:\n",
    "        cij = _return_length_weighted_w(data).full()[0]\n",
    "        cij = cij / cij.sum()\n",
    "   \n",
    "    peri = data.length\n",
    "    ai   = data.area\n",
    "    \n",
    "    aux_sum = np.add(np.array(list((peri / ai))), np.array(list((peri / ai))).reshape((len(list((peri / ai))),1)))\n",
    "    \n",
    "    max_pa = max(peri / ai)\n",
    "    \n",
    "    num = np.multiply(np.multiply(manhattan_distances(data[['pi']]), cij), aux_sum).sum()\n",
    "    den = 4 * max_pa\n",
    "    \n",
    "    PARD = D - (num / den)\n",
    "    PARD\n",
    "    \n",
    "    return PARD\n",
    "\n",
    "\n",
    "class Perimeter_Area_Ratio_Spatial_Dissim:\n",
    "    \"\"\"\n",
    "    Calculation of Perimeter/Area Ratio Spatial Dissimilarity index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data          : a geopandas DataFrame with a 'geometry' column.\n",
    "    \n",
    "    group_pop_var : string\n",
    "                    The name of variable in data that contains the population size of the group of interest\n",
    "                    \n",
    "    total_pop_var : string\n",
    "                    The name of variable in data that contains the total population of the unit\n",
    "                    \n",
    "    std           : boolean\n",
    "                    A condition for standardisation of the weights matrices. \n",
    "                    If True, the values of cij in the formulas gets standardized and the overall sum is 1.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    statistic : float\n",
    "                Perimeter/Area Ratio Spatial Dissimilarity Index\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    In this example, we will calculate the degree of perimeter/area ratio spatial dissimilarity (PARD) for the Riverside County using the census tract data of 2010.\n",
    "    The group of interest is non-hispanic black people which is the variable nhblk10 in the dataset.\n",
    "    \n",
    "    Firstly, we need to read the data:\n",
    "    \n",
    "    >>> This example uses all census data that the user must provide your own copy of the external database.\n",
    "    >>> A step-by-step procedure for downloading the data can be found here: https://github.com/spatialucr/osnap/tree/master/osnap/data.\n",
    "    >>> After the user download the LTDB_Std_All_fullcount.zip and extract the files, the filepath might be something like presented below.\n",
    "    >>> filepath = '~/data/std_2010_fullcount.csv'\n",
    "    >>> census_2010 = pd.read_csv(filepath, encoding = \"ISO-8859-1\", sep = \",\")\n",
    "    \n",
    "    Then, we filter only for the desired county (in this case, Riverside County):\n",
    "    \n",
    "    >>> df = census_2010.loc[census_2010.county == \"Riverside County\"][['trtid10', 'pop10','nhblk10']]\n",
    "    \n",
    "    Then, we read the Riverside map data using geopandas (the county id is 06065):\n",
    "    \n",
    "    >>> map_url = 'https://raw.githubusercontent.com/renanxcortes/inequality-segregation-supplementary-files/master/Tracts_grouped_by_County/06065.json'\n",
    "    >>> map_gpd = gpd.read_file(map_url)\n",
    "    \n",
    "    It is necessary to harmonize the data type of the dataset and the geopandas in order to work the merging procedure.\n",
    "    Later, we extract only the columns that will be used.\n",
    "    \n",
    "    >>> map_gpd['INTGEOID10'] = pd.to_numeric(map_gpd[\"GEOID10\"])\n",
    "    >>> gdf_pre = map_gpd.merge(df, left_on = 'INTGEOID10', right_on = 'trtid10')\n",
    "    >>> gdf = gdf_pre[['geometry', 'pop10', 'nhblk10']]\n",
    "    \n",
    "    The value is estimated below.\n",
    "    \n",
    "    >>> perimeter_area_ratio_spatial_dissim_index = Perimeter_Area_Ratio_Spatial_Dissim(gdf, 'nhblk10', 'pop10')\n",
    "    >>> perimeter_area_ratio_spatial_dissim_index.statistic\n",
    "    0.31260876347432687\n",
    "            \n",
    "    Notes\n",
    "    -----\n",
    "    The formula is based on Hong, Seong-Yun, David O'Sullivan, and Yukio Sadahiro. \"Implementing spatial segregation measures in R.\" PloS one 9.11 (2014): e113767.\n",
    "    \n",
    "    Original paper by Wong, David WS. \"Spatial indices of segregation.\" Urban studies 30.3 (1993): 559-572.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, group_pop_var, total_pop_var, std = True):\n",
    "\n",
    "        self.statistic = _perimeter_area_ratio_spatial_dissim(data, group_pop_var, total_pop_var, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.27777778, 0.        , 0.44444444, 0.        , 0.27777778],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       , 0.        ]])"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
